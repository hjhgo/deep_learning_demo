{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minst_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjhgo/deep_learning_demo/blob/master/minst_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZRReZP52T_h1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0c46c87-742c-4e98-fa54-fb7971c239df"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LduQ6mKOUAX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a53a906b-4932-471e-9792-0ea00d9ec276"
      },
      "cell_type": "code",
      "source": [
        "!rm m*"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'm*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXRlfNXccKkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0db875f-9095-4564-b542-172d9312278e"
      },
      "cell_type": "code",
      "source": [
        "!rm checkpoint"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'checkpoint': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_-OSknlZT_Wd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "XG3DtyTyN83H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "ff55fc63-7439-4585-e5f9-38127a310912"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.contrib.layers as layers\n",
        "\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    def get_input(features,labels):\n",
        "        input_x = tf.expand_dims(features,axis=-1)\n",
        "        input_y = tf.squeeze(labels)\n",
        "\n",
        "        return input_x,input_y\n",
        "\n",
        "    def conv_net(x):\n",
        "        initializer = tf.random_normal_initializer(stddev=0.01)\n",
        "        with tf.name_scope(\"conv1\"):\n",
        "            filter = tf.get_variable(\"filter-%s\" % 32, [5, 5, 1, 32],\n",
        "                                     initializer=initializer)\n",
        "\n",
        "            x = tf.nn.conv2d(x, filter=filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            x = tf.nn.max_pool(x, ksize=(1, 2, 2, 1), strides=[1, 2, 2, 1], padding='VALID')\n",
        "            if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "                with tf.name_scope(\"drop_out\"):\n",
        "                    x = tf.nn.dropout(x, keep_prob=params.drop_out)\n",
        "        \n",
        "        with tf.name_scope(\"conv2\"):\n",
        "            # conv\n",
        "            filter = tf.get_variable(\"filter-%s\" % 64, [5, 5, 32, 64],\n",
        "                                     initializer=initializer)\n",
        "            x = tf.nn.conv2d(x, filter=filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            x = tf.nn.max_pool(x, ksize=(1, 2, 2, 1), strides=[1, 2, 2, 1], padding='VALID')\n",
        "            if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "                with tf.name_scope(\"drop_out\"):\n",
        "                    x = tf.nn.dropout(x, keep_prob=params.drop_out)\n",
        "\n",
        "        with tf.name_scope(\"conv3\"):\n",
        "            # conv\n",
        "            filter = tf.get_variable(\"filter-%s\" % 258, [5, 5, 64, 258],\n",
        "                                     initializer=initializer)\n",
        "            x = tf.nn.conv2d(x, filter=filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            x = tf.nn.max_pool(x, ksize=(1, 2, 2, 1), strides=[1, 2, 2, 1], padding='VALID')\n",
        "            if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "                with tf.name_scope(\"drop_out\"):\n",
        "                    x = tf.nn.dropout(x, keep_prob=params.drop_out)            \n",
        "       \n",
        "        return x\n",
        "\n",
        "    def fullconnected(x):\n",
        "        if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "            with tf.name_scope(\"drop_out\"):\n",
        "                x = tf.nn.dropout(x, keep_prob=params.drop_out)\n",
        "                \n",
        "        with tf.name_scope(\"full_connect1\"):\n",
        "            x = tf.layers.dense(x, units=params.hidden_size, activation=\"elu\")\n",
        "\n",
        "        with tf.name_scope(\"full_connect2\"):\n",
        "            logist = tf.layers.dense(x, units=params.num_class)\n",
        "        return logist\n",
        "\n",
        "    x , y = get_input(features, labels)\n",
        "    x = conv_net(x)\n",
        "    size = 1\n",
        "    for i in x.get_shape().as_list()[1:]:\n",
        "        size*=i\n",
        "    x = tf.reshape(x,shape=[-1,size])\n",
        "    logits = fullconnected(x)\n",
        "    prediction = tf.argmax(logits,axis=1)\n",
        "    cross_entropy = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y,logits=logits))\n",
        "    train_op= layers.optimize_loss(loss=cross_entropy,\n",
        "                                   global_step=tf.train.get_global_step(),\n",
        "                                   learning_rate=params.learning_rate,\n",
        "                                   optimizer=\"Adam\",\n",
        "                                   clip_gradients=params.clip_max,\n",
        "                                   )\n",
        "    return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                      predictions={\"logits\":logits,\"prediction\":prediction},\n",
        "                                      loss=cross_entropy,\n",
        "                                      train_op=train_op,\n",
        "                                      eval_metric_ops={\"accuracy\":tf.metrics.accuracy(labels,prediction)})\n",
        "\n",
        "\n",
        "# import tensorflow.contrib.training as train\n",
        "# train.HParams\n",
        "\n",
        "def create_estimator_and_spec():\n",
        "    model_param =tf.contrib.training.HParams(\n",
        "                num_class = 10,\n",
        "                hidden_size = 256,\n",
        "                clip_max = 5.0,\n",
        "                drop_out = 0.7,\n",
        "                learning_rate = 0.01,\n",
        "                batch_size = 128\n",
        "    )\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=\"./\",\n",
        "        save_checkpoints_secs=300,\n",
        "        save_summary_steps=100)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn = model_fn,\n",
        "        config = run_config,\n",
        "        params=model_param\n",
        "    )\n",
        "\n",
        "    return estimator\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    estimator = create_estimator_and_spec()\n",
        "    \n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x=x_train.astype(np.float32),y=y_train.astype(np.int32),shuffle=True,batch_size=128,num_epochs=10)\n",
        "    test_input_fn = tf.estimator.inputs.numpy_input_fn(x=x_test.astype(np.float32),y=y_test.astype(np.int32),shuffle=False,batch_size=128,num_epochs=1)\n",
        "\n",
        "    # estimator.train(input_fn=train_input_fn)\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn)\n",
        "    evel_spec = tf.estimator.EvalSpec(input_fn=test_input_fn)\n",
        "#    estimator.train(input_fn=train_input_fn)\n",
        "    tf.estimator.train_and_evaluate(estimator=estimator,train_spec=train_spec,eval_spec=evel_spec)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7f8e580ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./model.ckpt-454\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 454 into ./model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3885007, step = 455\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}